{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to OpenCV**\n",
    "\n",
    "These set of notebooks correspond to the tutorial provided by [ProgrammingKnowldge](https://www.youtube.com/channel/UCs6nmQViDpUw0nuIx9c_WvA) YouTube channel which consists of a series of videos as a way of introducing OpenCV with Python. You can also check the full tutorial (around 9 hours and 23 minutes of length) at the following [link](https://www.youtube.com/watch?v=N81PCpADwKQ).\n",
    "\n",
    "In this particular notebook, we'll see an introduction to OpenCV, including:\n",
    "\n",
    "- How to read, write and show images on OpenCV\n",
    "- How to read, write and show videos using cameras\n",
    "- Drawing geometric shapes on camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. What is OpenCV?**\n",
    "\n",
    "First of all, OpenCV is an open source Computer Vision library. \n",
    "\n",
    "Computer Vision \"*is the field of computer science that focuses on replicating parts of the complexity of the human vision system and enabling computers to identify and process objects in images and videos in the same way that humans do*\". Is what allows cimputers to see and process data as humans do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. How do computers see images?**\n",
    "\n",
    "Images are represented as matrixes defined by the height and width of pixels the images is composed. Also, we have `grey-scaled images` which are represented by only one matrix of of these pixels (one numerical value for each pixel) and `colored images` which allows to represent more real images. The latter ones are composed by three matrixes in which each of these represent one of the basic colors humans see: red, yellow and blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **3. Manipulating Images**\n",
    "\n",
    "First, we'll have to import OpenCV, and let's also check the version installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make easier the import of the images lets change the current directory to where the files are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Aristi\\\\Documents\\\\Cursos\\\\OpenCV'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Aristi\\\\Documents\\\\Cursos\\\\OpenCV\\\\SampleImages'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Reading images**\n",
    "\n",
    "Let's see how we can read images by using the `imread()` method. The first argument is the image to load, the second specifies the way the image should be read: 1 corresponds to colored image, 0 corresponds to grayscale image and -1 loads the image unchanged (including alpha channels that are several transformations that an image can have such as transparency).\n",
    "\n",
    "Also, in order to show the images we are importing we can use the `imshow()` method. Where the first argument of the method is the name of the window in which your image will be opened and the second argument should be the image (generally assigned in a variable).\n",
    "\n",
    "As this method appeared to crash on Google Colab, we are using the `cv2_imshow()` from the `google.colab.patches` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.imread('lena.jpg',1)\n",
    "\n",
    "cv2.imshow('colored-image',img_1)\n",
    "quit_img = cv2.waitKey(0)\n",
    "\n",
    "if quit_img == 27:  # Quitting with 'esc' key\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2 = cv2.imread('lena.jpg',0)\n",
    "\n",
    "cv2.imshow('colored-image',img_2)\n",
    "quit_img = cv2.waitKey(0)\n",
    "\n",
    "if quit_img == 27:  # Quitting with 'esc' key\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Writing images**\n",
    "\n",
    "For writing an image, we are using the `imwrite()` method that works similarly as the reading method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('lena-copy.png', img_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'true' value above shows that the operation was done succesfully. So the image was saved with the name 'lena-copy.png' in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Manipulating videos using cameras**\n",
    "\n",
    "These methods will work with both live cameras and videos that are stored as a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Reading a video**\n",
    "\n",
    "In both cases we will be using the  `VideoCapture()` method, in which if we enter the name of the video file we want to read, that would captured. Instead, if we want to use our own camera, we have to add as the argument the index of the camera we want to used that by default it's either 0 or -1 (these are equivalent). Also if we want to use several cameras we can use 1 or 2 for the second camera as the argument and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to capture the frame continuosly we have to make a while loop. The `read` method that we'll be using will return `True` if the frame is available and the frame will be saved in the following frame variable.\n",
    "\n",
    "Also, we have to invoke again the `imshow()` method for showing the video that is being captured.\n",
    "\n",
    "For being able to stop the video capturing, we'll use the `destroyAllWindows()` method that will respond after the `waitKey()`. It's important also to release the resources used, that can be done with `.release()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('frame_name', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make the video captured grey defining a new variable with the method `cvtColor()` where the first argument is the source video and the second argument is the conversion we want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame_name', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see one more example but with a file stored within a folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame_name', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using this `cap` instance you can read some properties of the video that is being captured. \n",
    "\n",
    "The first we're going to see is if the video is opened or not. This method is `isOpened()`. This is usually used for avoiding giving the wrong file name or the wrong camera number (as it is going to return False).\n",
    "\n",
    "Another property is the `get()` method, where we can provide the property id and assign it into a variable. For example, for obtaining the width (`CAP_PROP_FRAME_WIDTH`) and the height (`CAP_PROP_FRAME_HEIGHT`).\n",
    "\n",
    "You may also find the full description of propoerties in the [OpenCV Documentation > VideoCaptureProperties](https://docs.opencv.org/3.4/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame width:  640.0\n",
      "Frame width:  480.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "aux = 0   # This is for obtaining the props just once\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if aux == 0:\n",
    "        print('Frame width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('Frame height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        aux += 1\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame_name', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Writing / Saving a video**\n",
    "\n",
    "We can save videos using the `VideoWriter()` class, in which the first argument is the name we want to give to the file. \n",
    "\n",
    "The second argument is the fourcc code is used for specifying the video codec (is software or hardware that compresses and decompresses digital video). These can be found on the [fourcc webpage](https://www.fourcc.org/codecs.php). We can initialize the fourcc with the `VideoWriter_fourcc()` method.\n",
    "\n",
    "The third argument is the number of FPS (frames per second).\n",
    "\n",
    "The fourth argument is the size of the frames, which we already know that we are capturing in (640, 480) pixels' frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        out.write(frame)\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame_name', gray)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this video will be saved in the BGR colored frame because we used the 'frame' variable in the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
