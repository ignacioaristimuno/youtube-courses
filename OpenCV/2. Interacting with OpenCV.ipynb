{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Interacting with OpenCV**\n",
    "\n",
    "These set of notebooks correspond to the tutorial provided by [ProgrammingKnowldge](https://www.youtube.com/channel/UCs6nmQViDpUw0nuIx9c_WvA) YouTube channel which consists of a series of videos as a way of introducing OpenCV with Python. You can also check the full tutorial (around 9 hours and 23 minutes of length) at the following [link](https://www.youtube.com/watch?v=N81PCpADwKQ).\n",
    "\n",
    "In this particular notebook, we'll see how to interact with OpenCV, including:\n",
    "\n",
    "- Drawing shapes on images\n",
    "- Setting camera parameters and showing datetime information in videos\n",
    "- Handling mouse events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "path = 'C:\\\\Users\\\\Aristi\\\\Documents\\\\Cursos\\\\OpenCV\\\\SampleImages'\n",
    "os.chdir(path)\n",
    "\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Drawing shapes on images**\n",
    "\n",
    "To draw a line into an image, we'll have to overwrite the image using the `line()` method, in which the first argument is the image itself, the second argument is the coordinate of point1, the third argument is the coordinate of point 2, the fourth argument is the color, and the fifth and last argument is the color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg', 1)\n",
    "img = cv2.line(img, (0, 0), (255, 255), (0, 0, 255), 5) # Color in BGR format\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make an arrowed line with the `arrowedLine()` method which has the same arguments, taking into consideration that the arrow will be pointing in the direction of the second point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg', 1)\n",
    "img = cv2.arrowedLine(img, (100, 80), (255, 255), (230, 30, 130), 5) # Color in BGR format\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For drawing rectangles we can use the `rectangle()` method, in which we have the same first five arguments (img, point1(top left), point2(bottom right), color, thickness, ...) and then we can give a sixth argument that would be the line type and the last argument is the shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg', 1)\n",
    "img = cv2.arrowedLine(img, (100, 80), (235, 235), (230, 30, 130), 5) # Color in BGR format\n",
    "img = cv2.rectangle(img, (245, 245), (350, 350), (230, 130, 80), 5)\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also make some differente preferences as filling the recangle (value of -1 in the thickness argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg', 1)\n",
    "img = cv2.arrowedLine(img, (100, 80), (235, 235), (230, 30, 130), 5) # Color in BGR format\n",
    "img = cv2.rectangle(img, (245, 245), (350, 350), (230, 130, 80), -1)\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For drawing circles we use the `circles()` method which takes the image as the first argument, the second argument is the center of the circule, the third argument is the radius, and the 4th adn 5th arguments are the color and thickness respectively.\n",
    "\n",
    "The complete set of methods it's on the [OpenCV Documentation > Drawing functions](https://docs.opencv.org/3.4/d6/d6e/group__imgproc__draw.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg', 1)\n",
    "img = cv2.arrowedLine(img, (100, 80), (235, 235), (230, 30, 130), 5) # Color in BGR format\n",
    "img = cv2.circle(img, (270, 270), 30, (230, 130, 80), 4)\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Adding text into images**\n",
    "\n",
    "Once again we'll overwrite our image with the `putText()` method. Once again the first argument is the image, then the text we want to display, as the 3rd argument the starting point of the text we'll display, the 4th argument is the font face (given by a variable that we'll assign with `.FONT_`). Then, the 5th argument is the font size, the 6th argument is the font color, the 7th is the thickness, and the last one is the linea type (fiven by `LINE_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg', 1)\n",
    "img = cv2.circle(img, (270, 270), 30, (230, 130, 80), 4)\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img = cv2.putText(img, 'Circle in the eye', (150, 220), fontface, 1, (230, 130, 80), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Creating images with numpy**\n",
    "\n",
    "Also, instead of importing an existing image we can create an image by defining a three-dimensional matrix (in the case of color scale image) or just a matrix (for gray-scale images).\n",
    "\n",
    "For example with `np.zeros()` method in which we can give the height, width and the scale (3 is colored), and then the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.zeros([512, 512, 3], np.uint8)\n",
    "img = cv2.circle(img, (270, 270), 30, (230, 130, 80), 4)\n",
    "\n",
    "fontface = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img = cv2.putText(img, 'Just a circle', (172, 220), fontface, 1, (230, 130, 80), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image-with-line', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Setting camera parameters**\n",
    "\n",
    "We can use the `cap.set()` method to set some values. Generally we can set all the properties that we can read with the `cap.get()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame original width:  640.0\n",
      "Frame original height:  480.0\n",
      "Frame set width:  320.0\n",
      "Frame set height:  240.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print('Frame original width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print('Frame original height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 200)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 200)\n",
    "\n",
    "aux = 0\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Video Capture', frame)\n",
    "    if aux == 0:\n",
    "        print('Frame set width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('Frame set height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        aux += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the camera acts accordingly to it's resolution. The minimun resoltion is 320 pixels width. What would happen if we set the frame resolution to 300x300?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame original width:  640.0\n",
      "Frame original height:  480.0\n",
      "Frame set width:  352.0\n",
      "Frame set heigth:  288.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print('Frame original width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print('Frame original height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 351)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 270)\n",
    "\n",
    "aux = 0\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Video Capture', frame)\n",
    "    if aux == 0:\n",
    "        print('Frame set width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('Frame set heigth: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        aux += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't find in the documentation why the width is taken down from 300 (in the set method) to 288, but my personal conclusion is that, in order to mantain the ratio between width and height, both values must be integer and also, not all values are posible (i.e. only widths multiple of 32 are possible).\n",
    "\n",
    "Also, the maximum frame size is limited by the maximum resolution of the default camera. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame original width:  640.0\n",
      "Frame original height:  480.0\n",
      "Frame set width:  1280.0\n",
      "Frame set height:  720.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print('Frame original width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print('Frame original height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 2000)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2000)\n",
    "\n",
    "aux = 0\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Video Capture', frame)\n",
    "    if aux == 0:\n",
    "        print('Frame set width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print('Frame set height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        aux += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Showing text in a video**\n",
    "\n",
    "### **5.1 Showing frame width and height**\n",
    "First of all we'll be showing the frame width and height within the video we are capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame original width:  640.0\n",
      "Frame original height:  480.0\n",
      "Frame width: 1280\n",
      "Frame height: 720\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print('Frame original width: ', cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print('Frame original height: ', cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 2000)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2000)\n",
    "\n",
    "aux = 0\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_w = 'Frame width: ' + str(round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "    text_h = 'Frame height: ' + str(round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    \n",
    "    frame = cv2.putText(frame, text_w, (10, 50), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    frame = cv2.putText(frame, text_h, (10, 100), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Video Capture', frame)\n",
    "    \n",
    "    if aux == 0:\n",
    "        print(text_w)\n",
    "        print(text_h)\n",
    "        aux += 1\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Showing date and time in a video**\n",
    "\n",
    "For this, we'll be using the `datetime` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 2000)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2000)\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    datet = str(datetime.datetime.now().strftime('%H:%M:%S %d/%b/%Y'))\n",
    "    \n",
    "    frame = cv2.putText(frame, datet, (10, 40), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Video Capture', frame)\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Handling mouse events**\n",
    "\n",
    "He can handle different mouse events such as left click, double left click, right clicks, etc. We can see all the available events within OpenCV by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_FLAG_ALTKEY\n",
      "EVENT_FLAG_CTRLKEY\n",
      "EVENT_FLAG_LBUTTON\n",
      "EVENT_FLAG_MBUTTON\n",
      "EVENT_FLAG_RBUTTON\n",
      "EVENT_FLAG_SHIFTKEY\n",
      "EVENT_LBUTTONDBLCLK\n",
      "EVENT_LBUTTONDOWN\n",
      "EVENT_LBUTTONUP\n",
      "EVENT_MBUTTONDBLCLK\n",
      "EVENT_MBUTTONDOWN\n",
      "EVENT_MBUTTONUP\n",
      "EVENT_MOUSEHWHEEL\n",
      "EVENT_MOUSEMOVE\n",
      "EVENT_MOUSEWHEEL\n",
      "EVENT_RBUTTONDBLCLK\n",
      "EVENT_RBUTTONDOWN\n",
      "EVENT_RBUTTONUP\n"
     ]
    }
   ],
   "source": [
    "for i in dir(cv2):\n",
    "      if 'EVENT' in i:\n",
    "          print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we'll create a mouse callback function that will take place when the mouse event occurs, with the help of the `setMouseCallback()` method.\n",
    "\n",
    "The first argument of the method is the window name (that should be the same everywhere), and as a second argument the callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  211    y:  146\n",
      "X:  251    y:  280\n"
     ]
    }
   ],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print('X: ', x,'   y: ',  y)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        coord_str = str(x) + ', ' + str(y)\n",
    "        cv2.putText(img, coord_str, (x,y), font, 0.5, (0, 0, 0), 1)\n",
    "        cv2.imshow('image', img)\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        blue = img[y, x, 0]\n",
    "        green = img[y, x, 1]\n",
    "        red = img[y, x, 2]\n",
    "        BGR = '(' + str(blue) + ', ' + str(green) + ', ' + str(red) + ')'\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img, BGR, (x,y), font, 0.5, (30, 100, 210), 1)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "img = np.ones((512, 512, 3), np.uint8)*255\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe, it's more visual if we do this in a real photo. Also, let's change the right click text so it's the opposite color of the pixel selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  31    y:  65\n",
      "X:  304    y:  188\n",
      "X:  274    y:  303\n"
     ]
    }
   ],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        \n",
    "        print('X: ', x,'   y: ',  y)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        coord_str = str(x) + ', ' + str(y)\n",
    "        \n",
    "        cv2.putText(img, coord_str, (x,y), font, 0.5, (0, 0, 0), 1)\n",
    "        cv2.imshow('image', img)\n",
    "        \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        \n",
    "        blue = img[y, x, 0]\n",
    "        green = img[y, x, 1]\n",
    "        red = img[y, x, 2]\n",
    "        \n",
    "        BGR = '(' + str(blue) + ', ' + str(green) + ', ' + str(red) + ')'\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        \n",
    "        cv2.putText(img, BGR, (x,y), font, 0.5, (255 - int(blue), 255 - int(green), 255 - int(red)), 1)\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll draw small circles (points) and when the second cirle is drawn, a line should appear connecting both circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        \n",
    "        cv2.circle(img, (x, y), 5, (0, 0, 255), -1)\n",
    "        points.append((x, y))\n",
    "        \n",
    "        if len(points) >= 2:\n",
    "            cv2.line(img, points[-1], points[-2], (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.imshow('image', img)\n",
    "points = []\n",
    "\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
